{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading\n",
    "Tutorial by Jonas Wilfert, Tobias Thummerer\n",
    "\n",
    "泅ｧ This tutorial is under revision and will be replaced by an up-to-date version soon 泅ｧ\n",
    "\n",
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:38:52.427000Z",
     "iopub.status.busy": "2024-02-03T18:38:51.958000Z",
     "iopub.status.idle": "2024-02-03T18:38:52.662000Z",
     "shell.execute_reply": "2024-02-03T18:38:52.584000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Josef Kircher, Johannes Stoljar, Jonas Wilfert\n",
    "# Licensed under the MIT license. \n",
    "# See LICENSE (https://github.com/thummeto/FMI.jl/blob/main/LICENSE) file in the project root for details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "This Julia Package *FMI.jl* is motivated by the use of simulation models in Julia. Here the FMI specification is implemented. FMI (*Functional Mock-up Interface*) is a free standard ([fmi-standard.org](https://fmi-standard.org/)) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. The user can thus use simulation models in the form of an FMU (*Functional Mock-up Units*). Besides loading the FMU, the user can also set values for parameters and states and simulate the FMU both as co-simulation and model exchange simulation.\n",
    "\n",
    "## Introduction to the example\n",
    "This example shows how to parallelize the computation of an FMU in FMI.jl. We can compute a batch of FMU-evaluations in parallel with different initial settings.\n",
    "Parallelization can be achieved using multithreading or using multiprocessing. This example shows **multithreading**, check `multiprocessing.ipynb` for multiprocessing.\n",
    "Advantage of multithreading is a lower communication overhead as well as lower RAM usage.\n",
    "However in some cases multiprocessing can be faster as the garbage collector is not shared.\n",
    "\n",
    "\n",
    "The model used is a one-dimensional spring pendulum with friction. The object-orientated structure of the *SpringFrictionPendulum1D* can be seen in the following graphic.\n",
    "\n",
    "![svg](https://github.com/thummeto/FMI.jl/blob/main/docs/src/examples/pics/SpringFrictionPendulum1D.svg?raw=true)  \n",
    "\n",
    "\n",
    "## Target group\n",
    "The example is primarily intended for users who work in the field of simulations. The example wants to show how simple it is to use FMUs in Julia.\n",
    "\n",
    "\n",
    "## Other formats\n",
    "Besides, this [Jupyter Notebook](https://github.com/thummeto/FMI.jl/blob/examples/examples/src/multithreading.ipynb) there is also a [Julia file](https://github.com/thummeto/FMI.jl/blob/examples/examples/src/multithreading.jl) with the same name, which contains only the code cells and for the documentation there is a [Markdown file](https://github.com/thummeto/FMI.jl/blob/examples/examples/src/multithreading.md) corresponding to the notebook.  \n",
    "\n",
    "\n",
    "## Getting started\n",
    "\n",
    "### Installation prerequisites\n",
    "|     | Description                       | Command                   | Alternative                                    |   \n",
    "|:----|:----------------------------------|:--------------------------|:-----------------------------------------------|\n",
    "| 1.  | Enter Package Manager via         | ]                         |                                                |\n",
    "| 2.  | Install FMI via                   | add FMI                   | add \" https://github.com/ThummeTo/FMI.jl \"     |\n",
    "| 3.  | Install FMIZoo via                | add FMIZoo                | add \" https://github.com/ThummeTo/FMIZoo.jl \"  |\n",
    "| 4.  | Install FMICore via               | add FMICore               | add \" https://github.com/ThummeTo/FMICore.jl \" |\n",
    "| 5.  | Install Folds via                 | add Folds                 |                                                |\n",
    "| 6.  | Install BenchmarkTools via        | add BenchmarkTools        |                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code section\n",
    "\n",
    "To run the example, the previously installed packages must be included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:38:52.662000Z",
     "iopub.status.busy": "2024-02-03T18:38:52.662000Z",
     "iopub.status.idle": "2024-02-03T18:39:35.621000Z",
     "shell.execute_reply": "2024-02-03T18:39:35.621000Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "using FMI\n",
    "using FMIZoo\n",
    "using Folds\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check the amount of available threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:39:35.746000Z",
     "iopub.status.busy": "2024-02-03T18:39:35.621000Z",
     "iopub.status.idle": "2024-02-03T18:39:36.214000Z",
     "shell.execute_reply": "2024-02-03T18:39:36.214000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the number of available threads doesn't match your expections, you can increase the number of threads available to the Julia process like described [here](https://docs.julialang.org/en/v1/manual/multi-threading/#Starting-Julia-with-multiple-threads)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation setup\n",
    "\n",
    "Next, the start time and end time of the simulation are set. Here we also decide the size of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:39:36.246000Z",
     "iopub.status.busy": "2024-02-03T18:39:36.246000Z",
     "iopub.status.idle": "2024-02-03T18:39:38.700000Z",
     "shell.execute_reply": "2024-02-03T18:39:38.700000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Vector{Float64}}:\n",
       " [0.9968840597086824, 0.73097623178669]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_start = 0.0\n",
    "t_step = 0.1\n",
    "t_stop = 10.0\n",
    "tspan = (t_start, t_stop)\n",
    "tData = collect(t_start:t_step:t_stop)\n",
    "\n",
    "# Best if batchSize is a multiple of the threads/cores\n",
    "batchSize = Threads.nthreads()\n",
    "\n",
    "# Define an array of arrays randomly\n",
    "input_values = collect(collect.(eachrow(rand(batchSize,2))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to instantiate one FMU for each parallel execution, as they cannot be easily shared among different threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:39:38.700000Z",
     "iopub.status.busy": "2024-02-03T18:39:38.700000Z",
     "iopub.status.idle": "2024-02-03T18:39:45.109000Z",
     "shell.execute_reply": "2024-02-03T18:39:45.109000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{FMU2}:\n",
       " Model name:\tSpringPendulum1D\n",
       "Type:\t\t1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a single FMU to compare the performance\n",
    "realFMU = fmiLoad(\"SpringPendulum1D\", \"Dymola\", \"2022x\")\n",
    "\n",
    "# the FMU batch\n",
    "realFMUBatch = [fmiLoad(\"SpringPendulum1D\", \"Dymola\", \"2022x\") for _ in 1:batchSize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a helper function to calculate the FMU solution and combine it into an Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:39:45.109000Z",
     "iopub.status.busy": "2024-02-03T18:39:45.109000Z",
     "iopub.status.idle": "2024-02-03T18:39:45.297000Z",
     "shell.execute_reply": "2024-02-03T18:39:45.297000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runCalcFormatted (generic function with 2 methods)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function runCalcFormatted(fmu::FMU2, x0::Vector{Float64}, recordValues::Vector{String}=[\"mass.s\", \"mass.v\"])\n",
    "    data = fmiSimulateME(fmu, tspan; recordValues=recordValues, saveat=tData, x0=x0, showProgress=false, dtmax=1e-4)\n",
    "    return reduce(hcat, data.states.u)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a single evaluation is pretty quick, therefore the speed can be better tested with BenchmarkTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:39:45.297000Z",
     "iopub.status.busy": "2024-02-03T18:39:45.297000Z",
     "iopub.status.idle": "2024-02-03T18:40:27.463000Z",
     "shell.execute_reply": "2024-02-03T18:40:27.463000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 2 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m 窶ｦ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.789 s\u001b[22m\u001b[39m 窶ｦ \u001b[35m  2.820 s\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmin 窶ｦ max\u001b[90m): \u001b[39m1.75% 窶ｦ 1.13%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.805 s              \u001b[22m\u001b[39m\u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m1.44%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ﾂｱ \u001b[32mﾏソu001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.805 s\u001b[22m\u001b[39m ﾂｱ \u001b[32m21.930 ms\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmean ﾂｱ ﾏソu001b[90m):  \u001b[39m1.44% ﾂｱ 0.44%\n",
       "\n",
       "  \u001b[34m笆\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m笆\u001b[39m \u001b[39m \n",
       "  \u001b[34m笆\u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[32m笆―u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆\u001b[39m \u001b[39m笆―n",
       "  2.79 s\u001b[90m         Histogram: frequency by time\u001b[39m        2.82 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m520.54 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m14203445\u001b[39m."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark data = runCalcFormatted(realFMU, rand(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Threaded Batch Execution\n",
    "To compute a batch we can collect multiple evaluations. In a single threaded context we can use the same FMU for every call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:40:27.479000Z",
     "iopub.status.busy": "2024-02-03T18:40:27.479000Z",
     "iopub.status.idle": "2024-02-03T18:40:49.945000Z",
     "shell.execute_reply": "2024-02-03T18:40:49.945000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Threaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 2 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m 窶ｦ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.791 s\u001b[22m\u001b[39m 窶ｦ \u001b[35m  2.817 s\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmin 窶ｦ max\u001b[90m): \u001b[39m1.18% 窶ｦ 1.90%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.804 s              \u001b[22m\u001b[39m\u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m1.54%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ﾂｱ \u001b[32mﾏソu001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.804 s\u001b[22m\u001b[39m ﾂｱ \u001b[32m18.383 ms\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmean ﾂｱ ﾏソu001b[90m):  \u001b[39m1.54% ﾂｱ 0.50%\n",
       "\n",
       "  \u001b[34m笆\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m笆\u001b[39m \u001b[39m \n",
       "  \u001b[34m笆\u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[32m笆―u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆\u001b[39m \u001b[39m笆―n",
       "  2.79 s\u001b[90m         Histogram: frequency by time\u001b[39m        2.82 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m520.54 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m14203448\u001b[39m."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"Single Threaded\")\n",
    "@benchmark collect(runCalcFormatted(realFMU, i) for i in input_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreaded Batch Execution\n",
    "In a multithreaded context we have to provide each thread it's own fmu, as they are not thread safe.\n",
    "To spread the execution of a function to multiple threads, the library `Folds` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:40:49.945000Z",
     "iopub.status.busy": "2024-02-03T18:40:49.945000Z",
     "iopub.status.idle": "2024-02-03T18:41:14.678000Z",
     "shell.execute_reply": "2024-02-03T18:41:14.678000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Threaded"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 2 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m 窶ｦ \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.752 s\u001b[22m\u001b[39m 窶ｦ \u001b[35m 2.762 s\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmin 窶ｦ max\u001b[90m): \u001b[39m1.66% 窶ｦ 1.10%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m2.757 s             \u001b[22m\u001b[39m\u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m1.38%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ﾂｱ \u001b[32mﾏソu001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m2.757 s\u001b[22m\u001b[39m ﾂｱ \u001b[32m6.953 ms\u001b[39m  \u001b[90m笏浬u001b[39m GC \u001b[90m(\u001b[39mmean ﾂｱ ﾏソu001b[90m):  \u001b[39m1.38% ﾂｱ 0.40%\n",
       "\n",
       "  \u001b[34m笆\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m笆\u001b[39m \u001b[39m \n",
       "  \u001b[34m笆\u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[32m笆―u001b[39m\u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆―u001b[39m笆\u001b[39m \u001b[39m笆―n",
       "  2.75 s\u001b[90m        Histogram: frequency by time\u001b[39m        2.76 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m520.54 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m14203463\u001b[39m."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"Multi Threaded\")\n",
    "@benchmark Folds.collect(runCalcFormatted(fmu, i) for (fmu, i) in zip(realFMUBatch, input_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a significant speed-up in the median execution time. But: The speed-up is often much smaller than `Threads.nthreads()`, this has different reasons. For a rule of thumb, the speed-up should be around `n/2` on a `n`-core-processor with `n` threads for the Julia process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unload FMU\n",
    "\n",
    "After calculating the data, the FMU is unloaded and all unpacked data on disc is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-03T18:41:14.678000Z",
     "iopub.status.busy": "2024-02-03T18:41:14.678000Z",
     "iopub.status.idle": "2024-02-03T18:41:15.459000Z",
     "shell.execute_reply": "2024-02-03T18:41:15.459000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Nothing}:\n",
       " nothing"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmiUnload(realFMU)\n",
    "fmiUnload.(realFMUBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this tutorial it is shown how multi threading with `Folds.jl` can be used to improve the performance for calculating a Batch of FMUs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
