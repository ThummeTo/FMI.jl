# Multiprocessing
Tutorial by Jonas Wilfert, Tobias Thummerer

## License
Copyright (c) 2021 Tobias Thummerer, Lars Mikelsons, Josef Kircher, Johannes Stoljar, Jonas Wilfert

Licensed under the MIT license. See [LICENSE](https://github.com/thummeto/FMI.jl/blob/main/LICENSE) file in the project root for details.

## Motivation
This Julia Package *FMI.jl* is motivated by the use of simulation models in Julia. Here the FMI specification is implemented. FMI (*Functional Mock-up Interface*) is a free standard ([fmi-standard.org](http://fmi-standard.org/)) that defines a container and an interface to exchange dynamic models using a combination of XML files, binaries and C code zipped into a single file. The user can thus use simulation models in the form of an FMU (*Functional Mock-up Units*). Besides loading the FMU, the user can also set values for parameters and states and simulate the FMU both as co-simulation and model exchange simulation.

## Introduction to the example
This example shows how to parallelize the computation of an FMU in FMI.jl. We can compute a batch of FMU-evaluations in parallel with different initial settings.
Parallelization can be achieved using multithreading or using multiprocessing. This example shows **multiprocessing**, check `multithreading.ipynb` for multithreading.
Advantage of multithreading is a lower communication overhead as well as lower RAM usage.
However, in some cases multiprocessing can be faster as the garbage collector is not shared.


The model used is a one-dimensional spring pendulum with friction. The object-orientated structure of the *SpringFrictionPendulum1D* can be seen in the following graphic.

![svg](https://github.com/thummeto/FMI.jl/blob/main/docs/src/examples/pics/SpringFrictionPendulum1D.svg?raw=true)  


## Target group
The example is primarily intended for users who work in the field of simulations. The example wants to show how simple it is to use FMUs in Julia.


## Other formats
Besides, this [Jupyter Notebook](https://github.com/thummeto/FMI.jl/blob/main/example/distributed.ipynb) there is also a [Julia file](https://github.com/thummeto/FMI.jl/blob/main/example/distributed.jl) with the same name, which contains only the code cells and for the documentation there is a [Markdown file](https://github.com/thummeto/FMI.jl/blob/main/docs/src/examples/distributed.md) corresponding to the notebook.  


## Getting started

### Installation prerequisites
|     | Description                       | Command                   | Alternative                                    |   
|:----|:----------------------------------|:--------------------------|:-----------------------------------------------|
| 1.  | Enter Package Manager via         | ]                         |                                                |
| 2.  | Install FMI via                   | add FMI                   | add " https://github.com/ThummeTo/FMI.jl "     |
| 3.  | Install FMIZoo via                | add FMIZoo                | add " https://github.com/ThummeTo/FMIZoo.jl "  |
| 4.  | Install FMICore via               | add FMICore               | add " https://github.com/ThummeTo/FMICore.jl " |
| 5.  | Install BenchmarkTools via        | add BenchmarkTools        |                                                |

## Code section



Adding your desired amount of processes:


```julia
using Distributed
n_procs = 4
addprocs(n_procs; exeflags=`--project=$(Base.active_project()) --threads=auto`, restrict=false)
```




    4-element Vector{Int64}:
     2
     3
     4
     5



To run the example, the previously installed packages must be included. 


```julia
# imports
@everywhere using FMI
@everywhere using FMIZoo
@everywhere using BenchmarkTools
```

Checking that we workers have been correctly initialized:


```julia
workers()

@everywhere println("Hello World!")

# The following lines can be uncommented for more advanced informations about the subprocesses
# @everywhere println(pwd())
# @everywhere println(Base.active_project())
# @everywhere println(gethostname())
# @everywhere println(VERSION)
# @everywhere println(Threads.nthreads())
```

          From worker 3:	Hello World!
          From worker 2:	Hello World!
          From worker 4:	Hello World!
    Hello World!
          From worker 5:	Hello World!


### Simulation setup

Next, the batch size and input values are defined.


```julia

# Best if batchSize is a multiple of the threads/cores
batchSize = 16

# Define an array of arrays randomly
input_values = collect(collect.(eachrow(rand(batchSize,2))))
```




    16-element Vector{Vector{Float64}}:
     [0.8522478954672708, 0.7209431226036078]
     [0.909306253617912, 0.6209402039669427]
     [0.4596043790366431, 0.2389289971087898]
     [0.4934930898692784, 0.8535888352523144]
     [0.9008166213933464, 0.48097066683100986]
     [0.30695689796078574, 0.8999444231606255]
     [0.5676033936598277, 0.0170782917662895]
     [0.43299006096393633, 0.6018253815343202]
     [0.8863999765881179, 0.5879607966583695]
     [0.9250498940640433, 0.676688143062196]
     [0.5927221115688299, 0.13661645859930105]
     [0.5274125466018458, 0.6019662513572075]
     [0.7212113914423361, 0.6184174840746639]
     [0.5904677676104344, 0.9526791253940541]
     [0.7887765751716826, 0.32324579460992675]
     [0.867048815207933, 0.728198232394913]



### Shared Module
For Distributed we need to embed the FMU into its own `module`. This prevents Distributed from trying to serialize and send the FMU over the network, as this can cause issues. This module needs to be made available on all processes using `@everywhere`.


```julia
@everywhere module SharedModule
    using FMIZoo
    using FMI

    t_start = 0.0
    t_step = 0.1
    t_stop = 10.0
    tspan = (t_start, t_stop)
    tData = collect(t_start:t_step:t_stop)

    model_fmu = FMIZoo.fmiLoad("SpringPendulum1D", "Dymola", "2022x")
end
```

    ‚îå Info: fmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_ywfEtU/SpringPendulum1D`.
    ‚îî @ FMIImport /home/runner/.julia/packages/FMIImport/DJ6oi/src/FMI2_ext.jl:75
    ‚îå Info: fmi2Load(...): FMU resources location is `file:////tmp/fmijl_ywfEtU/SpringPendulum1D/resources`
    ‚îî @ FMIImport /home/runner/.julia/packages/FMIImport/DJ6oi/src/FMI2_ext.jl:190
    ‚îå Info: fmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
    ‚îî @ FMIImport /home/runner/.julia/packages/FMIImport/DJ6oi/src/FMI2_ext.jl:193
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_WvJUQ4/SpringPendulum1D`.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_kty5Tc/SpringPendulum1D`.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_ElhvF8/SpringPendulum1D`.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU resources location is `file:////tmp/fmijl_WvJUQ4/SpringPendulum1D/resources`
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU resources location is `file:////tmp/fmijl_kty5Tc/SpringPendulum1D/resources`
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU resources location is `file:////tmp/fmijl_ElhvF8/SpringPendulum1D/resources`
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Unzip(...): Successfully unzipped 153 files at `/tmp/fmijl_RvaFkX/SpringPendulum1D`.
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU resources location is `file:////tmp/fmijl_RvaFkX/SpringPendulum1D/resources`
    [36m[1m[ [22m[39m[36m[1mInfo: [22m[39mfmi2Load(...): FMU supports both CS and ME, using CS as default if nothing specified.


We define a helper function to calculate the FMU and combine it into a Matrix.


```julia
@everywhere function runCalcFormatted(fmu, x0, recordValues=["mass.s", "mass.v"])
    data = fmiSimulateME(fmu, SharedModule.t_start, SharedModule.t_stop; recordValues=recordValues, saveat=SharedModule.tData, x0=x0, showProgress=false, dtmax=1e-4)
    return reduce(hcat, data.states.u)
end
```

Running a single evaluation is pretty quick, therefore the speed can be better tested with BenchmarkTools.


```julia
@benchmark data = runCalcFormatted(SharedModule.model_fmu, rand(2))
```




    BenchmarkTools.Trial: 16 samples with 1 evaluation.
     Range [90m([39m[36m[1mmin[22m[39m ‚Ä¶ [35mmax[39m[90m):  [39m[36m[1m301.517 ms[22m[39m ‚Ä¶ [35m343.653 ms[39m  [90m‚îä[39m GC [90m([39mmin ‚Ä¶ max[90m): [39m6.30% ‚Ä¶ 8.37%
     Time  [90m([39m[34m[1mmedian[22m[39m[90m):     [39m[34m[1m325.148 ms               [22m[39m[90m‚îä[39m GC [90m([39mmedian[90m):    [39m5.92%
     Time  [90m([39m[32m[1mmean[22m[39m ¬± [32mœÉ[39m[90m):   [39m[32m[1m324.977 ms[22m[39m ¬± [32m 11.601 ms[39m  [90m‚îä[39m GC [90m([39mmean ¬± œÉ[90m):  [39m6.39% ¬± 1.09%
    
      [39m‚ñÅ[39m [39m [39m [39m [39m [39m [39m [39m [39m‚ñÅ[39m [39m [39m [39m [39m [39m [39m‚ñÅ[39m [39m [39m [39m [39m‚ñÅ[39m [39m [39m‚ñÅ[39m [39m [39m [39m‚ñÅ[39m‚ñÅ[39m [39m [39m [34m‚ñÅ[39m[32m [39m[39m‚ñÅ[39m [39m [39m [39m [39m [39m [39m [39m [39m‚ñà[39m‚ñà[39m [39m [39m [39m [39m [39m‚ñÅ[39m‚ñÅ[39m [39m [39m [39m [39m [39m [39m [39m‚ñÅ[39m [39m 
      [39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[34m‚ñà[39m[32m‚ñÅ[39m[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m‚ñà[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m [39m‚ñÅ
      302 ms[90m           Histogram: frequency by time[39m          344 ms [0m[1m<[22m
    
     Memory estimate[90m: [39m[33m146.80 MiB[39m, allocs estimate[90m: [39m[33m3002431[39m.



### Single Threaded Batch Execution
To compute a batch we can collect multiple evaluations. In a single threaded context we can use the same FMU for every call.


```julia
println("Single Threaded")
@benchmark collect(runCalcFormatted(SharedModule.model_fmu, i) for i in input_values)
```

    Single Threaded





    BenchmarkTools.Trial: 1 sample with 1 evaluation.
     Single result which took [34m5.128 s[39m (6.62% GC) to evaluate,
     with a memory estimate of [33m2.29 GiB[39m, over [33m48038884[39m allocations.



### Multithreaded Batch Execution
In a multithreaded context we have to provide each thread its own fmu, as they are not thread safe.
To spread the execution of a function to multiple processes, the function `pmap` can be used.


```julia
println("Multi Threaded")
@benchmark pmap(i -> runCalcFormatted(SharedModule.model_fmu, i), input_values)
```

    Multi Threaded





    BenchmarkTools.Trial: 2 samples with 1 evaluation.
     Range [90m([39m[36m[1mmin[22m[39m ‚Ä¶ [35mmax[39m[90m):  [39m[36m[1m3.323 s[22m[39m ‚Ä¶ [35m  3.367 s[39m  [90m‚îä[39m GC [90m([39mmin ‚Ä¶ max[90m): [39m0.00% ‚Ä¶ 0.00%
     Time  [90m([39m[34m[1mmedian[22m[39m[90m):     [39m[34m[1m3.345 s              [22m[39m[90m‚îä[39m GC [90m([39mmedian[90m):    [39m0.00%
     Time  [90m([39m[32m[1mmean[22m[39m ¬± [32mœÉ[39m[90m):   [39m[32m[1m3.345 s[22m[39m ¬± [32m31.349 ms[39m  [90m‚îä[39m GC [90m([39mmean ¬± œÉ[90m):  [39m0.00% ¬± 0.00%
    
      [34m‚ñà[39m[39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [32m [39m[39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m [39m‚ñà[39m [39m 
      [34m‚ñà[39m[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[32m‚ñÅ[39m[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñÅ[39m‚ñà[39m [39m‚ñÅ
      3.32 s[90m         Histogram: frequency by time[39m        3.37 s [0m[1m<[22m
    
     Memory estimate[90m: [39m[33m81.44 KiB[39m, allocs estimate[90m: [39m[33m1198[39m.



As you can see, there is a significant speed-up in the median execution time. But: The speed-up is often much smaller than `n_procs` (or the number of physical cores of your CPU), this has different reasons. For a rule of thumb, the speed-up should be around `n/2` on a `n`-core-processor with `n` Julia processes.

### Unload FMU

After calculating the data, the FMU is unloaded and all unpacked data on disc is removed.


```julia
@everywhere fmiUnload(SharedModule.model_fmu)
```

### Summary

In this tutorial it is shown how multiprocessing with `Distributed.jl` can be used to improve the performance for calculating a Batch of FMUs.
